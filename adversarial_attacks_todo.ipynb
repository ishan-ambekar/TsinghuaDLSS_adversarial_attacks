{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Adversarial Attack\n",
    "\n",
    "We assume that you have read the [Adversarial Attacks Tutorial](./adversarial_attacks_tutorial.ipynb) carefully and run that notebook from scratch. \n",
    "\n",
    "In this notebook, you are required to process adversarial attacks for a small subset of [ImageNet Dataset](http://www.image-net.org/). We prepared 100 images from different categories (in `./input_dir/`), and the labels are encoded in `./input_dir/clean_image.list`.\n",
    "\n",
    "For evaluation, each adversarial image generated by the attack model will be fed to an evaluation model, and we will calculate the successful rate of adversarial attacks. **The adversarial images that can fool the evaluation model and also the perturbations are less than *Max_Distance* will be considered as a success**, where the perturbations are measured by the L2 distance between the adversarial image and original image.\n",
    "\n",
    "There are three tasks:\n",
    "- **White-box attack**: the adversarial examples are crafted for the pretrained **MobileNetV2** model, and evaluated on the same **MobileNetV2** model.\n",
    "- **Black-box attack**: the adversarial examples are crafted for the pretrained **MobileNetV2** model, but evaluated on the **MobileNet** model, which is different from MobileNetV2.\n",
    "- **Black-box attack (after submission)**: you are required to submit the generated adversarial examples at last, and we will evaluate your adversarial examples on another model, which is invisible for you.\n",
    "\n",
    "### Goal\n",
    "\n",
    "We provide a simple FGSM example here, and you are required to implement your own attack methods to **achieve the attack successful rate as high as possible** (for all three tasks).\n",
    "\n",
    "At last, you are required to submit this jupyter notebook and the generated adversarial images.\n",
    "The final grade will be scored according to the **white-box successful rate**, **black-box successful rate**, **white-box (after submission) successful rate**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from time import perf_counter\n",
    "from utils import *\n",
    "import tensornets as nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images\n",
    "We provided 100 images from different categories in `./input_dir/`, and the labels are encoded in `./input_dir/clean_image.list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "with open('./input_dir/clean_image.list', 'r') as f:\n",
    "    img_lines = f.readlines()\n",
    "    for img_line in img_lines:\n",
    "        imgname, label = img_line.strip('\\n').split(' ')\n",
    "        images.append((imgname, int(label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing\n",
    "\n",
    "Each input image must be preprocessed before fed into the models, such as normalization(subtracting the mean and then dividing by the standard deviation). In addition, each generated adversarial image must be reversely processed.\n",
    "Note that different pretrained models in Tensorflow require different preprocessing.\n",
    "We provided several `preprocess` and `reverse_preprocess` function for different deep networks in `./utils.py`.\n",
    "\n",
    "By default, the two functions are designed for mobilenet models.\n",
    "```python\n",
    "preprocess(image, model=\"mobilenet\")\n",
    "reverse_preprocess(image, model=\"mobilenet\")\n",
    "```\n",
    "\n",
    "If you want to change to other models, see `./utils.py` for more details.\n",
    "\n",
    "We have downloaded several popular pretrained models, you can adopt these models as the attacked model.\n",
    "## Pretrained Models in tensornets (nets)\n",
    "    'DenseNet121', 'DenseNet169', 'DenseNet201', \n",
    "    'Inception1', 'Inception2', 'Inception3', 'Inception4', 'InceptionResNet2',\n",
    "    'MobileNet25', 'MobileNet50', 'MobileNet75', MobileNet100', \n",
    "    'MobileNet35v2', 'MobileNet50v2', 'MobileNet75v2', 'MobileNet100v2', 'MobileNet130v2', 'MobileNet140v2', \n",
    "    'NASNetAlarge', 'NASNetAmobile', 'PNASNetlarge',\n",
    "    'ResNet50', 'ResNet101', 'ResNet152', 'ResNet50v2', 'ResNet101v2', 'ResNet152v2', 'ResNet200v2', \n",
    "    'ResNeXt50c32', 'ResNeXt101c32', 'ResNeXt101c64', 'WideResNet50',\n",
    "    'VGG16', 'VGG19', \n",
    "    'SqueezeNet'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Attack Method\n",
    "\n",
    "### TODO: implement your own attack methods.\n",
    "\n",
    "###  Tips:\n",
    "- We provide the simple FGSM attack method as an example here. You can try other attack methods (learned in this course), such as the iterative methods.\n",
    "- For black-box attack, we adopt the `MobileNetV2` as the attacked model, and the generated adversarial images may failed in `MobileNet` (which indicates poor transferability). You can try other attacked models (except `MobileNet`) or model ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attack:\n",
    "    def __init__(self, input_image):\n",
    "        self.input_image = input_image\n",
    "        \n",
    "        # loss function\n",
    "        self.loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        \n",
    "        # TODO: you may change your target model.\n",
    "        # load the model which will be attacked\n",
    "        self.attacked_model = nets.MobileNet50v2(input_image, reuse=tf.AUTO_REUSE)\n",
    "        \n",
    "    def generate_adversarial_example(self, input_label, attack_mode, attack_method, eps, T=0, miu=0):\n",
    "        input_image = self.input_image\n",
    "        prediction = self.attacked_model\n",
    "        loss = self.loss_object(input_label, prediction)\n",
    "        \n",
    "        # TODO: implement your own attack methods.\n",
    "        if attack_mode=='whitebox':\n",
    "            if attack_method=='FGSM':\n",
    "                # Get the gradients of the loss w.r.t to the input image.\n",
    "                gradient = tf.gradients(loss, input_image)\n",
    "                # Get the sign of the gradients to create the perturbation (FGSM)\n",
    "                signed_grad = tf.sign(gradient)[0]\n",
    "                # Epsilon in FGSM, you can try another value.\n",
    "                adv_image = input_image + eps * signed_grad\n",
    "                # Clip the generated image between -1 and 1. Note that different pretrained models require different ranges.\n",
    "                adv_image = tf.clip_by_value(adv_image, -1, 1)\n",
    "\n",
    "            elif attack_method=='IFGSM':\n",
    "                print(str(T) + ' iterations')\n",
    "                \n",
    "                adv_x = input_image\n",
    "                for i in range(1, T+1):\n",
    "                    alpha = eps / float(i)\n",
    "                    gradient = tf.gradients(loss, adv_x)\n",
    "                    signed_grad = tf.sign(gradient)[0]\n",
    "                    adv_x = adv_x + alpha * signed_grad\n",
    "                    adv_x = tf.clip_by_value(adv_x, -1, 1)\n",
    "                    prediction = nets.MobileNet50v2(adv_x, reuse=tf.AUTO_REUSE)\n",
    "                    loss = self.loss_object(input_label, prediction)\n",
    "\n",
    "                adv_image = adv_x\n",
    "\n",
    "            elif attack_method=='MIFGSM':\n",
    "                print(str(T) + ' iterations' + ' miu=' + str(miu))\n",
    "                \n",
    "                adv_x = input_image\n",
    "                g=0\n",
    "                for i in range(1,T+1):\n",
    "                    alpha = eps / float(i)\n",
    "                    gradient = tf.gradients(loss, adv_x)\n",
    "                    norm_gradient = tf.norm(gradient, ord=1, axis=1) #TODO\n",
    "                    g = miu*g + (gradient/norm_gradient)\n",
    "                    \n",
    "                    signed_grad = tf.sign(g)[0]\n",
    "                    adv_x = adv_x + alpha * signed_grad\n",
    "                    adv_x = tf.clip_by_value(adv_x, -1, 1)\n",
    "                    prediction = nets.MobileNet50v2(adv_x, reuse=tf.AUTO_REUSE)\n",
    "                    loss = self.loss_object(input_label, prediction)\n",
    "\n",
    "                adv_image = adv_x\n",
    "                \n",
    "        elif attack_mode=='blackbox':\n",
    "            if attack_method=='FGSM':\n",
    "                # Get the gradients of the loss w.r.t to the input image.\n",
    "                gradient = tf.gradients(loss, input_image)\n",
    "                # Get the sign of the gradients to create the perturbation (FGSM)\n",
    "                signed_grad = tf.sign(gradient)[0]\n",
    "                # Epsilon in FGSM, you can try another value.\n",
    "                adv_image = input_image + eps * signed_grad\n",
    "                # Clip the generated image between -1 and 1. Note that different pretrained models require different ranges.\n",
    "                adv_image = tf.clip_by_value(adv_image, -1, 1)\n",
    "\n",
    "            elif attack_method=='IFGSM':\n",
    "                print(str(T) + ' iterations')\n",
    "                \n",
    "                adv_x = input_image\n",
    "                for i in range(1, T+1):\n",
    "                    alpha = eps / float(i)\n",
    "                    gradient = tf.gradients(loss, adv_x)\n",
    "                    signed_grad = tf.sign(gradient)[0]\n",
    "                    adv_x = adv_x + alpha * signed_grad\n",
    "                    adv_x = tf.clip_by_value(adv_x, -1, 1)\n",
    "                    prediction = nets.MobileNet50v2(adv_x, reuse=tf.AUTO_REUSE)\n",
    "                    loss = self.loss_object(input_label, prediction)\n",
    "\n",
    "                adv_image = adv_x\n",
    "\n",
    "            elif attack_method=='MIFGSM':\n",
    "                print(str(T) + ' iterations' + ' miu=' + str(miu))\n",
    "                \n",
    "                adv_x = input_image\n",
    "                g=0\n",
    "                for i in range(1,T+1):\n",
    "                    alpha = eps / float(i)\n",
    "                    gradient = tf.gradients(loss, adv_x)\n",
    "                    norm_gradient = tf.norm(gradient, ord=1, axis=1) \n",
    "                    g = miu*g + (gradient/norm_gradient)\n",
    "                    \n",
    "                    signed_grad = tf.sign(g)[0]\n",
    "                    adv_x = adv_x + alpha * signed_grad\n",
    "                    adv_x = tf.clip_by_value(adv_x, -1, 1)\n",
    "                    prediction = nets.MobileNet50v2(adv_x, reuse=tf.AUTO_REUSE)\n",
    "                    loss = self.loss_object(input_label, prediction)\n",
    "\n",
    "                adv_image = adv_x\n",
    "                \n",
    "            elif attack_method=='MIFGSM_ensemble':\n",
    "                print(str(T) + ' iterations' + ' miu=' + str(miu))\n",
    "                \n",
    "                adv_x = input_image\n",
    "                g=0\n",
    "                for i in range(1,T+1):\n",
    "                    alpha = eps / float(i)\n",
    "                    gradient = tf.gradients(loss, adv_x)\n",
    "                    norm_gradient = tf.norm(gradient, ord=1, axis=1) \n",
    "                    g = miu*g + (gradient/norm_gradient)\n",
    "                    \n",
    "                    signed_grad = tf.sign(gradient)[0]\n",
    "                    adv_x = adv_x + alpha * signed_grad\n",
    "                    adv_x = tf.clip_by_value(adv_x, -1, 1)\n",
    "                    \n",
    "                    prediction1 = nets.MobileNet25(input_image, reuse=tf.AUTO_REUSE)\n",
    "                    prediction2 = nets.MobileNet50(input_image, reuse=tf.AUTO_REUSE)\n",
    "                    prediction3 = nets.MobileNet75(input_image, reuse=tf.AUTO_REUSE)\n",
    "                    prediction4 = nets.MobileNet100(input_image, reuse=tf.AUTO_REUSE)\n",
    "                    prediction5 = nets.MobileNet35v2(input_image, reuse=tf.AUTO_REUSE)\n",
    "                    prediction6 = nets.MobileNet50v2(input_image, reuse=tf.AUTO_REUSE)\n",
    "                    prediction7 = nets.MobileNet75v2(input_image, reuse=tf.AUTO_REUSE)\n",
    "                    prediction8 = nets.MobileNet100v2(input_image, reuse=tf.AUTO_REUSE)\n",
    "                    prediction9 = nets.MobileNet130v2(input_image, reuse=tf.AUTO_REUSE)\n",
    "                    prediction10 = nets.MobileNet140v2(input_image, reuse=tf.AUTO_REUSE)\n",
    "                    \n",
    "                    # Ensemble loss\n",
    "                    loss1 = self.loss_object(input_label, prediction1)\n",
    "                    loss2 = self.loss_object(input_label, prediction2)\n",
    "                    loss3 = self.loss_object(input_label, prediction4)\n",
    "                    loss4 = self.loss_object(input_label, prediction4)\n",
    "                    loss5 = self.loss_object(input_label, prediction5)\n",
    "                    loss6 = self.loss_object(input_label, prediction6)\n",
    "                    loss7 = self.loss_object(input_label, prediction7)\n",
    "                    loss8 = self.loss_object(input_label, prediction8)\n",
    "                    loss9 = self.loss_object(input_label, prediction9)\n",
    "                    loss10 = self.loss_object(input_label, prediction10)\n",
    "                    \n",
    "                    w = [0.25, 0.20, 0.35, 0.20]\n",
    "                    loss = - w[0]*loss1 + w[1]*loss2 + w[2]*loss3 + w[3]*loss4 + w[4]*loss5 + w[5]*loss6 + \n",
    "                            w[6]*loss7 + w[7]*loss + w[8]*loss9 + w[9]*loss10\n",
    "                \n",
    "                adv_image = adv_x\n",
    "        # END TODO\n",
    "        \n",
    "        return adv_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Define the evaluation functions for both white-box and black-box attack.\n",
    "**You are not allowed to modify these codes.**\n",
    "\n",
    "- For white-box attack, the adversarial images are evaluated on the `MobileNetv2` model.\n",
    "- For black-box attack, the adversarial images are evaluated on the `MobileNet` model. Therefore, you can not use the same `MobileNet` model as the attacked model.\n",
    "\n",
    "The `Max_Distance` equals to 5.0 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_Distance = 5.0\n",
    "\n",
    "class WhiteBox_Evaluation:\n",
    "    def __init__(self, adv_image):\n",
    "        self.adv_image = adv_image\n",
    "        self.eval_model = nets.MobileNet50v2(adv_image, reuse=tf.AUTO_REUSE)\n",
    "        \n",
    "    def get_adv_label(self):\n",
    "        adv_probs  = self.eval_model\n",
    "        adv_label = tf.argmax(adv_probs,1)\n",
    "        return adv_label\n",
    "    \n",
    "class BlackBox_Evaluation:\n",
    "    def __init__(self, adv_image):\n",
    "        self.adv_image = adv_image\n",
    "        self.eval_model = nets.MobileNet50(adv_image, reuse=tf.AUTO_REUSE)\n",
    "        \n",
    "    def get_adv_label(self):\n",
    "        adv_probs  = self.eval_model\n",
    "        adv_label = tf.argmax(adv_probs,1)\n",
    "        return adv_label\n",
    "    \n",
    "# init the attacker\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "# load and preprocess image\n",
    "input_path = tf.placeholder(dtype=tf.string)\n",
    "input_label = tf.placeholder(shape=None, dtype=tf.int32)\n",
    "image_raw = tf.io.read_file(input_path)\n",
    "image = tf.image.decode_jpeg(image_raw, channels=3)\n",
    "image = image[None, ...]\n",
    "\n",
    "def Attack_Session(attack_method, attack_mode, eps, T=0, miu=0):\n",
    "    print(attack_method, attack_mode, eps)\n",
    "    input_image = preprocess(image)\n",
    "    attacker = Attack(input_image)\n",
    "\n",
    "    # generate adversarial example\n",
    "    adv_image_t = attacker.generate_adversarial_example(input_label, attack_mode, attack_method, eps, T, miu)\n",
    "    eval_model_white = WhiteBox_Evaluation(adv_image_t)\n",
    "    eval_model_black = BlackBox_Evaluation(adv_image_t)\n",
    "\n",
    "    # measured by L2 distance\n",
    "    distance_t = tf.math.reduce_euclidean_norm(input_image - adv_image_t)\n",
    "\n",
    "    adv_label_white_t = eval_model_white.get_adv_label()\n",
    "    adv_label_black_t = eval_model_black.get_adv_label()\n",
    "\n",
    "    saved_image_t = reverse_preprocess(adv_image_t)[0]\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    _ = sess.run([attacker.attacked_model.pretrained(), eval_model_white.eval_model.pretrained(), eval_model_black.eval_model.pretrained()])\n",
    "    \n",
    "    if attack_mode=='whitebox':\n",
    "        success_cnt = 0\n",
    "        for idx, (imgname, label) in enumerate(images):\n",
    "            imgpath = './input_dir/' + imgname\n",
    "            run_list = [adv_image_t, distance_t, adv_label_white_t, saved_image_t]\n",
    "            feed_dict = {input_path: imgpath, input_label: label}\n",
    "\n",
    "            adv_image, distance, adv_label, saved_image = sess.run(run_list, feed_dict)\n",
    "            adv_label = adv_label[0]\n",
    "\n",
    "            # if the adversarial image can successfully fool the attacked model, and the perturbations are less than Max_Distance\n",
    "            if distance <= Max_Distance:\n",
    "                success_cnt += 1 if adv_label != label else 0\n",
    "            else:\n",
    "                print('Max Distance Larger than '+ str(Max_Distance) + ' ' + str(distance))\n",
    "                return\n",
    "            \n",
    "            print('{}: clean_label={:3d} adv_label={:3d} distance={:.2f}'.format(imgname,label,adv_label,distance))\n",
    "\n",
    "            # save the generated images to './output_dir'\n",
    "            saved_image = tf.image.encode_png(saved_image)\n",
    "            write_ops = tf.io.write_file('./output_dir/' + imgname, saved_image)\n",
    "            sess.run(write_ops)\n",
    "\n",
    "        print()\n",
    "        print('White-box attack successful rate: {}%'.format(success_cnt))\n",
    "        \n",
    "    elif attack_mode=='blackbox':\n",
    "        success_cnt = 0\n",
    "        for idx, (imgname, label) in enumerate(images):\n",
    "            imgpath = './input_dir/' + imgname\n",
    "            run_list = [adv_image_t, distance_t, adv_label_black_t, saved_image_t]\n",
    "            feed_dict = {input_path: imgpath, input_label: label}\n",
    "\n",
    "            adv_image, distance, adv_label, saved_image = sess.run(run_list, feed_dict)\n",
    "            adv_label = adv_label[0]\n",
    "\n",
    "            # if the adversarial image can successfully fool the attacked model, and the perturbations are less than Max_Distance\n",
    "            if distance <= Max_Distance:\n",
    "                success_cnt += 1 if adv_label != label else 0\n",
    "            else:\n",
    "                print('Max Distance Larger than '+ str(Max_Distance) + ' ' + str(distance))\n",
    "                return\n",
    "\n",
    "            print('{}: clean_label={:3d} adv_label={:3d} distance={:.2f}'.format(imgname,label,adv_label,distance))\n",
    "\n",
    "            # save the generated images to './output_dir'\n",
    "            saved_image = tf.image.encode_png(saved_image)\n",
    "            write_ops = tf.io.write_file('./output_dir/' + imgname, saved_image)\n",
    "            sess.run(write_ops)\n",
    "    \n",
    "        sess.close()\n",
    "            \n",
    "        print()\n",
    "        print('Black-box attack successful rate: {}%'.format(success_cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# White-Box Attack Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM whitebox 0.01286\n",
      "n02708093.JPEG: clean_label=409 adv_label=592 distance=4.24\n",
      "n03000134.JPEG: clean_label=489 adv_label=353 distance=4.95\n",
      "n03384352.JPEG: clean_label=561 adv_label=495 distance=4.73\n",
      "n03777754.JPEG: clean_label=662 adv_label=882 distance=4.98\n",
      "n03721384.JPEG: clean_label=642 adv_label=696 distance=4.94\n",
      "n03424325.JPEG: clean_label=570 adv_label=518 distance=4.91\n",
      "n03673027.JPEG: clean_label=628 adv_label=833 distance=4.99\n",
      "n02229544.JPEG: clean_label=312 adv_label=456 distance=4.99\n",
      "n07695742.JPEG: clean_label=932 adv_label=925 distance=4.98\n",
      "n02018207.JPEG: clean_label=137 adv_label= 98 distance=4.98\n",
      "n02107908.JPEG: clean_label=240 adv_label=178 distance=4.99\n",
      "n04026417.JPEG: clean_label=748 adv_label=414 distance=4.95\n",
      "n02444819.JPEG: clean_label=360 adv_label=  5 distance=4.99\n",
      "n02259212.JPEG: clean_label=317 adv_label=462 distance=4.99\n",
      "n02480495.JPEG: clean_label=365 adv_label=149 distance=4.97\n",
      "n02095889.JPEG: clean_label=190 adv_label=212 distance=4.98\n",
      "n03216828.JPEG: clean_label=536 adv_label=724 distance=4.88\n",
      "n01817953.JPEG: clean_label= 87 adv_label= 34 distance=4.99\n",
      "n02422106.JPEG: clean_label=351 adv_label=355 distance=4.99\n",
      "n04376876.JPEG: clean_label=845 adv_label=405 distance=4.04\n",
      "n02099267.JPEG: clean_label=205 adv_label=178 distance=4.97\n",
      "n04398044.JPEG: clean_label=849 adv_label=505 distance=4.91\n",
      "n04023962.JPEG: clean_label=747 adv_label=830 distance=4.97\n",
      "n02093256.JPEG: clean_label=179 adv_label=252 distance=4.97\n",
      "n03109150.JPEG: clean_label=512 adv_label=543 distance=4.37\n",
      "n12267677.JPEG: clean_label=988 adv_label=994 distance=4.98\n",
      "n02667093.JPEG: clean_label=399 adv_label=614 distance=4.96\n",
      "n03956157.JPEG: clean_label=727 adv_label=344 distance=4.74\n",
      "n02033041.JPEG: clean_label=142 adv_label=141 distance=4.99\n",
      "n02071294.JPEG: clean_label=148 adv_label=  2 distance=4.96\n",
      "n02704792.JPEG: clean_label=408 adv_label=975 distance=4.98\n",
      "n02013706.JPEG: clean_label=135 adv_label= 57 distance=4.98\n",
      "n02177972.JPEG: clean_label=307 adv_label= 78 distance=4.99\n",
      "n03042490.JPEG: clean_label=500 adv_label= 20 distance=4.99\n",
      "n01443537.JPEG: clean_label=  1 adv_label=738 distance=4.95\n",
      "n02093647.JPEG: clean_label=181 adv_label=296 distance=4.99\n",
      "n04536866.JPEG: clean_label=889 adv_label=763 distance=4.93\n",
      "n07717556.JPEG: clean_label=942 adv_label=925 distance=4.84\n",
      "n03016953.JPEG: clean_label=493 adv_label=493 distance=4.98\n",
      "n04493381.JPEG: clean_label=876 adv_label=391 distance=4.98\n",
      "n04590129.JPEG: clean_label=905 adv_label=799 distance=4.89\n",
      "n02769748.JPEG: clean_label=414 adv_label=614 distance=4.99\n",
      "n03063599.JPEG: clean_label=504 adv_label=647 distance=4.98\n",
      "n04065272.JPEG: clean_label=757 adv_label=847 distance=4.94\n",
      "n02012849.JPEG: clean_label=134 adv_label= 99 distance=4.98\n",
      "n02655020.JPEG: clean_label=397 adv_label= 63 distance=4.97\n",
      "n04548280.JPEG: clean_label=892 adv_label=883 distance=4.98\n",
      "n02129604.JPEG: clean_label=292 adv_label=568 distance=4.98\n",
      "n03393912.JPEG: clean_label=565 adv_label=458 distance=4.99\n",
      "n02110341.JPEG: clean_label=251 adv_label=683 distance=4.94\n",
      "n02791270.JPEG: clean_label=424 adv_label=739 distance=4.93\n",
      "n04251144.JPEG: clean_label=801 adv_label=445 distance=4.99\n",
      "n02443114.JPEG: clean_label=358 adv_label=336 distance=4.98\n",
      "n12144580.JPEG: clean_label=987 adv_label=952 distance=4.85\n",
      "n02966687.JPEG: clean_label=477 adv_label=492 distance=4.95\n",
      "n03584254.JPEG: clean_label=605 adv_label=435 distance=4.95\n",
      "n02110185.JPEG: clean_label=250 adv_label=200 distance=4.99\n",
      "n02790996.JPEG: clean_label=422 adv_label=469 distance=4.92\n",
      "n02815834.JPEG: clean_label=438 adv_label=438 distance=4.99\n",
      "n07831146.JPEG: clean_label=959 adv_label=965 distance=4.99\n",
      "n04311174.JPEG: clean_label=822 adv_label=666 distance=4.78\n",
      "n01955084.JPEG: clean_label=116 adv_label=126 distance=4.98\n",
      "n09332890.JPEG: clean_label=975 adv_label=185 distance=4.94\n",
      "n03197337.JPEG: clean_label=531 adv_label=464 distance=4.76\n",
      "n03467068.JPEG: clean_label=583 adv_label=760 distance=4.97\n",
      "n03201208.JPEG: clean_label=532 adv_label=765 distance=4.97\n",
      "n03485407.JPEG: clean_label=590 adv_label=810 distance=4.42\n",
      "n03873416.JPEG: clean_label=693 adv_label=148 distance=4.99\n",
      "n03131574.JPEG: clean_label=520 adv_label=516 distance=4.98\n",
      "n07754684.JPEG: clean_label=955 adv_label=996 distance=4.98\n",
      "n02086240.JPEG: clean_label=155 adv_label=204 distance=4.98\n",
      "n07836838.JPEG: clean_label=960 adv_label=941 distance=4.95\n",
      "n03160309.JPEG: clean_label=525 adv_label=672 distance=4.99\n",
      "n09399592.JPEG: clean_label=976 adv_label=525 distance=4.94\n",
      "n02777292.JPEG: clean_label=416 adv_label=639 distance=4.98\n",
      "n02326432.JPEG: clean_label=331 adv_label=193 distance=4.99\n",
      "n01664065.JPEG: clean_label= 33 adv_label= 32 distance=4.99\n",
      "n01537544.JPEG: clean_label= 14 adv_label=442 distance=4.99\n",
      "n07583066.JPEG: clean_label=924 adv_label=985 distance=4.95\n",
      "n02814860.JPEG: clean_label=437 adv_label=745 distance=4.56\n",
      "n04153751.JPEG: clean_label=783 adv_label=686 distance=4.40\n",
      "n03379051.JPEG: clean_label=560 adv_label=439 distance=4.98\n",
      "n04597913.JPEG: clean_label=910 adv_label=477 distance=4.99\n",
      "n03977966.JPEG: clean_label=734 adv_label=751 distance=4.94\n",
      "n04606251.JPEG: clean_label=913 adv_label=226 distance=4.98\n",
      "n01773157.JPEG: clean_label= 72 adv_label= 74 distance=4.98\n",
      "n01688243.JPEG: clean_label= 43 adv_label=309 distance=4.96\n",
      "n01829413.JPEG: clean_label= 93 adv_label= 93 distance=4.97\n",
      "n04525038.JPEG: clean_label=885 adv_label=957 distance=4.97\n",
      "n04049303.JPEG: clean_label=756 adv_label=525 distance=4.95\n",
      "n01877812.JPEG: clean_label=104 adv_label=330 distance=4.99\n",
      "n03394916.JPEG: clean_label=566 adv_label=451 distance=4.90\n",
      "n03794056.JPEG: clean_label=674 adv_label=563 distance=4.05\n",
      "n01530575.JPEG: clean_label= 10 adv_label= 13 distance=4.99\n",
      "n03207941.JPEG: clean_label=534 adv_label=807 distance=4.98\n",
      "n02109525.JPEG: clean_label=247 adv_label=196 distance=4.98\n",
      "n07697313.JPEG: clean_label=933 adv_label=940 distance=4.97\n",
      "n02489166.JPEG: clean_label=376 adv_label=381 distance=4.97\n",
      "n02794156.JPEG: clean_label=426 adv_label=884 distance=4.97\n",
      "n04131690.JPEG: clean_label=773 adv_label=604 distance=4.98\n",
      "\n",
      "White-box attack successful rate: 97%\n"
     ]
    }
   ],
   "source": [
    "Attack_Session('FGSM', 'whitebox', 0.01286)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IFGSM whitebox 0.006\n",
      "20 iterations\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-183ec6fed6aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAttack_Session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'IFGSM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'whitebox'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.006\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-5eda9dd29094>\u001b[0m in \u001b[0;36mAttack_Session\u001b[0;34m(attack_method, attack_mode, eps, T, miu)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# generate adversarial example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0madv_image_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattacker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_adversarial_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmiu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0meval_model_white\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWhiteBox_Evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_image_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0meval_model_black\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlackBox_Evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_image_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-fa21a3c196e9>\u001b[0m in \u001b[0;36mgenerate_adversarial_example\u001b[0;34m(self, input_label, attack_mode, attack_method, eps, T, miu)\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                     \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                     \u001b[0msigned_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0madv_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madv_x\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigned_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         unconnected_gradients)\n\u001b[0m\u001b[1;32m    159\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    657\u001b[0m           \u001b[0mloop_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnterGradWhileContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         out_grads = _AggregatedGrads(grads, op, gradient_uid, loop_state,\n\u001b[0;32m--> 659\u001b[0;31m                                      aggregation_method)\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mloop_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m           \u001b[0mloop_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExitGradWhileContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_AggregatedGrads\u001b[0;34m(grads, op, gradient_uid, loop_state, aggregation_method)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     raise ValueError(\n\u001b[1;32m   1015\u001b[0m         \"Invalid aggregation_method specified %s.\" % aggregation_method)\n\u001b[0;32m-> 1016\u001b[0;31m   \u001b[0mout_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_GetGrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_grad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloop_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Attack_Session('IFGSM', 'whitebox', eps=0.006, T=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIFGSM whitebox 0.006\n",
      "20 iterations miu=0.45\n",
      "n02708093.JPEG: clean_label=409 adv_label=606 distance=3.86\n",
      "n03000134.JPEG: clean_label=489 adv_label=353 distance=4.96\n",
      "n03384352.JPEG: clean_label=561 adv_label=495 distance=4.23\n",
      "n03777754.JPEG: clean_label=662 adv_label=882 distance=3.90\n",
      "n03721384.JPEG: clean_label=642 adv_label=696 distance=4.36\n",
      "n03424325.JPEG: clean_label=570 adv_label=612 distance=4.24\n",
      "n03673027.JPEG: clean_label=628 adv_label=833 distance=4.06\n",
      "n02229544.JPEG: clean_label=312 adv_label=456 distance=3.86\n",
      "n07695742.JPEG: clean_label=932 adv_label=925 distance=4.15\n",
      "n02018207.JPEG: clean_label=137 adv_label=135 distance=4.22\n",
      "n02107908.JPEG: clean_label=240 adv_label=178 distance=3.97\n",
      "n04026417.JPEG: clean_label=748 adv_label= 83 distance=4.56\n",
      "n02444819.JPEG: clean_label=360 adv_label=  5 distance=4.16\n",
      "n02259212.JPEG: clean_label=317 adv_label=462 distance=3.83\n",
      "n02480495.JPEG: clean_label=365 adv_label=341 distance=4.25\n",
      "n02095889.JPEG: clean_label=190 adv_label=212 distance=4.60\n",
      "n03216828.JPEG: clean_label=536 adv_label=517 distance=4.58\n",
      "n01817953.JPEG: clean_label= 87 adv_label= 34 distance=4.02\n",
      "n02422106.JPEG: clean_label=351 adv_label=355 distance=4.00\n",
      "n04376876.JPEG: clean_label=845 adv_label=405 distance=3.23\n",
      "n02099267.JPEG: clean_label=205 adv_label=246 distance=4.30\n",
      "n04398044.JPEG: clean_label=849 adv_label=505 distance=4.23\n",
      "n04023962.JPEG: clean_label=747 adv_label=982 distance=4.10\n",
      "n02093256.JPEG: clean_label=179 adv_label=252 distance=3.92\n",
      "n03109150.JPEG: clean_label=512 adv_label=543 distance=3.83\n",
      "n12267677.JPEG: clean_label=988 adv_label= 93 distance=4.34\n",
      "n02667093.JPEG: clean_label=399 adv_label=614 distance=4.75\n",
      "n03956157.JPEG: clean_label=727 adv_label=344 distance=3.54\n",
      "n02033041.JPEG: clean_label=142 adv_label=127 distance=4.11\n",
      "n02071294.JPEG: clean_label=148 adv_label=395 distance=4.55\n",
      "n02704792.JPEG: clean_label=408 adv_label=975 distance=4.58\n",
      "n02013706.JPEG: clean_label=135 adv_label=  9 distance=5.12\n",
      "n02177972.JPEG: clean_label=307 adv_label= 73 distance=3.79\n",
      "n03042490.JPEG: clean_label=500 adv_label= 20 distance=4.10\n",
      "n01443537.JPEG: clean_label=  1 adv_label=222 distance=4.22\n",
      "n02093647.JPEG: clean_label=181 adv_label=370 distance=4.06\n",
      "n04536866.JPEG: clean_label=889 adv_label=670 distance=3.74\n",
      "n07717556.JPEG: clean_label=942 adv_label=925 distance=3.90\n",
      "n03016953.JPEG: clean_label=493 adv_label=542 distance=4.63\n",
      "n04493381.JPEG: clean_label=876 adv_label=394 distance=4.35\n",
      "n04590129.JPEG: clean_label=905 adv_label=799 distance=4.36\n",
      "n02769748.JPEG: clean_label=414 adv_label=614 distance=4.49\n",
      "n03063599.JPEG: clean_label=504 adv_label=790 distance=4.42\n",
      "n04065272.JPEG: clean_label=757 adv_label=847 distance=4.32\n",
      "n02012849.JPEG: clean_label=134 adv_label=364 distance=4.54\n",
      "n02655020.JPEG: clean_label=397 adv_label= 63 distance=4.19\n",
      "n04548280.JPEG: clean_label=892 adv_label=855 distance=3.99\n",
      "n02129604.JPEG: clean_label=292 adv_label=568 distance=4.28\n",
      "n03393912.JPEG: clean_label=565 adv_label=860 distance=4.40\n",
      "n02110341.JPEG: clean_label=251 adv_label=683 distance=4.33\n",
      "n02791270.JPEG: clean_label=424 adv_label=389 distance=4.27\n",
      "n04251144.JPEG: clean_label=801 adv_label=445 distance=4.34\n",
      "n02443114.JPEG: clean_label=358 adv_label=336 distance=4.49\n",
      "n12144580.JPEG: clean_label=987 adv_label=952 distance=4.12\n",
      "n02966687.JPEG: clean_label=477 adv_label=406 distance=4.86\n",
      "n03584254.JPEG: clean_label=605 adv_label=435 distance=4.14\n",
      "n02110185.JPEG: clean_label=250 adv_label=200 distance=4.24\n",
      "n02790996.JPEG: clean_label=422 adv_label=579 distance=4.43\n",
      "n02815834.JPEG: clean_label=438 adv_label=900 distance=3.95\n",
      "n07831146.JPEG: clean_label=959 adv_label=965 distance=4.26\n",
      "n04311174.JPEG: clean_label=822 adv_label=737 distance=4.11\n",
      "n01955084.JPEG: clean_label=116 adv_label=126 distance=4.14\n",
      "n09332890.JPEG: clean_label=975 adv_label=185 distance=4.28\n",
      "n03197337.JPEG: clean_label=531 adv_label=464 distance=3.95\n",
      "n03467068.JPEG: clean_label=583 adv_label=760 distance=4.51\n",
      "n03201208.JPEG: clean_label=532 adv_label=765 distance=4.44\n",
      "n03485407.JPEG: clean_label=590 adv_label=999 distance=4.09\n",
      "n03873416.JPEG: clean_label=693 adv_label= 82 distance=4.22\n",
      "n03131574.JPEG: clean_label=520 adv_label=516 distance=4.54\n",
      "n07754684.JPEG: clean_label=955 adv_label=993 distance=4.57\n",
      "n02086240.JPEG: clean_label=155 adv_label=355 distance=4.56\n",
      "n07836838.JPEG: clean_label=960 adv_label=941 distance=4.60\n",
      "n03160309.JPEG: clean_label=525 adv_label=672 distance=4.04\n",
      "n09399592.JPEG: clean_label=976 adv_label=755 distance=3.97\n",
      "n02777292.JPEG: clean_label=416 adv_label=639 distance=4.05\n",
      "n02326432.JPEG: clean_label=331 adv_label=193 distance=4.03\n",
      "n01664065.JPEG: clean_label= 33 adv_label=221 distance=4.33\n",
      "n01537544.JPEG: clean_label= 14 adv_label=442 distance=4.05\n",
      "n07583066.JPEG: clean_label=924 adv_label=985 distance=4.61\n",
      "n02814860.JPEG: clean_label=437 adv_label=745 distance=3.20\n",
      "n04153751.JPEG: clean_label=783 adv_label=831 distance=4.06\n",
      "n03379051.JPEG: clean_label=560 adv_label=699 distance=4.85\n",
      "n04597913.JPEG: clean_label=910 adv_label= 63 distance=4.79\n",
      "n03977966.JPEG: clean_label=734 adv_label=595 distance=4.61\n",
      "n04606251.JPEG: clean_label=913 adv_label=255 distance=4.13\n",
      "n01773157.JPEG: clean_label= 72 adv_label=325 distance=4.09\n",
      "n01688243.JPEG: clean_label= 43 adv_label=309 distance=4.30\n",
      "n01829413.JPEG: clean_label= 93 adv_label=337 distance=4.77\n",
      "n04525038.JPEG: clean_label=885 adv_label=957 distance=4.25\n",
      "n04049303.JPEG: clean_label=756 adv_label=525 distance=4.32\n",
      "n01877812.JPEG: clean_label=104 adv_label=330 distance=4.33\n",
      "n03394916.JPEG: clean_label=566 adv_label=451 distance=4.48\n",
      "n03794056.JPEG: clean_label=674 adv_label=563 distance=3.40\n",
      "n01530575.JPEG: clean_label= 10 adv_label= 13 distance=3.94\n",
      "n03207941.JPEG: clean_label=534 adv_label=807 distance=4.25\n",
      "n02109525.JPEG: clean_label=247 adv_label=196 distance=4.39\n",
      "n07697313.JPEG: clean_label=933 adv_label=987 distance=4.67\n",
      "n02489166.JPEG: clean_label=376 adv_label=271 distance=4.65\n",
      "n02794156.JPEG: clean_label=426 adv_label=884 distance=4.32\n",
      "n04131690.JPEG: clean_label=773 adv_label=604 distance=4.14\n",
      "\n",
      "White-box attack successful rate: 99%\n"
     ]
    }
   ],
   "source": [
    "Attack_Session('MIFGSM', 'whitebox', eps=0.006, T=20, miu=0.45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black-Box Attack Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIFGSM blackbox 0.006\n",
      "20 iterations miu=0.5\n",
      "n02708093.JPEG: clean_label=409 adv_label=409 distance=3.86\n",
      "n03000134.JPEG: clean_label=489 adv_label=489 distance=4.96\n",
      "n03384352.JPEG: clean_label=561 adv_label=561 distance=4.23\n",
      "n03777754.JPEG: clean_label=662 adv_label=662 distance=3.90\n",
      "n03721384.JPEG: clean_label=642 adv_label=642 distance=4.36\n",
      "n03424325.JPEG: clean_label=570 adv_label=570 distance=4.24\n",
      "n03673027.JPEG: clean_label=628 adv_label=628 distance=4.06\n",
      "n02229544.JPEG: clean_label=312 adv_label=872 distance=3.86\n",
      "n07695742.JPEG: clean_label=932 adv_label=925 distance=4.15\n",
      "n02018207.JPEG: clean_label=137 adv_label=137 distance=4.22\n",
      "n02107908.JPEG: clean_label=240 adv_label=241 distance=3.97\n",
      "n04026417.JPEG: clean_label=748 adv_label=748 distance=4.56\n",
      "n02444819.JPEG: clean_label=360 adv_label=360 distance=4.16\n",
      "n02259212.JPEG: clean_label=317 adv_label=317 distance=3.83\n",
      "n02480495.JPEG: clean_label=365 adv_label=365 distance=4.25\n",
      "n02095889.JPEG: clean_label=190 adv_label=190 distance=4.60\n",
      "n03216828.JPEG: clean_label=536 adv_label=536 distance=4.58\n",
      "n01817953.JPEG: clean_label= 87 adv_label= 87 distance=4.02\n",
      "n02422106.JPEG: clean_label=351 adv_label=351 distance=4.00\n",
      "n04376876.JPEG: clean_label=845 adv_label=845 distance=3.23\n",
      "n02099267.JPEG: clean_label=205 adv_label=205 distance=4.30\n",
      "n04398044.JPEG: clean_label=849 adv_label=849 distance=4.23\n",
      "n04023962.JPEG: clean_label=747 adv_label=747 distance=4.10\n",
      "n02093256.JPEG: clean_label=179 adv_label=179 distance=3.92\n",
      "n03109150.JPEG: clean_label=512 adv_label=512 distance=3.83\n",
      "n12267677.JPEG: clean_label=988 adv_label=988 distance=4.34\n",
      "n02667093.JPEG: clean_label=399 adv_label=399 distance=4.75\n",
      "n03956157.JPEG: clean_label=727 adv_label=727 distance=3.54\n",
      "n02033041.JPEG: clean_label=142 adv_label=142 distance=4.11\n",
      "n02071294.JPEG: clean_label=148 adv_label=148 distance=4.55\n",
      "n02704792.JPEG: clean_label=408 adv_label=408 distance=4.58\n",
      "Max Distance Larger than 5.0 5.124583\n"
     ]
    }
   ],
   "source": [
    "Attack_Session('MIFGSM', 'blackbox', eps=0.006, T=20, miu=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
